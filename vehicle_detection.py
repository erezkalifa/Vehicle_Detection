# -*- coding: utf-8 -*-
"""Vehicle_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T7QV-4YFUmZEJpI0VI8h9FOC3735MMN-
"""

!pip install opencv-python numpy
!pip install ultralytics
!pip install gradio ultralytics opencv-python matplotlib

import gradio as gr
import os
import cv2
import numpy as np
from ultralytics import YOLO

# Load YOLO model
model = YOLO("yolov8n.pt")

# Define vehicle classes (YOLO Class IDs)
vehicle_classes = [2, 3, 5, 7]  # 2: Car, 3: Motorcycle, 5: Bus, 7: Truck

# Dataset folder path (update if needed)
dataset_folder = "/content/dataset"

# Function to list available dataset files
def list_dataset_files():
    if not os.path.exists(dataset_folder):
        return ["❌ Dataset folder not found!"]

    files = [f for f in os.listdir(dataset_folder) if f.endswith((".jpg", ".png", ".mp4"))]
    return files if files else ["⚠️ No images or videos found in dataset!"]

# Function to preprocess image with denoising and contrast enhancement
def preprocess_image(image):
    # Apply optimized denoising (lower strength)
    denoised_image = cv2.fastNlMeansDenoisingColored(image, None, 5, 5, 7, 15)

    # Apply mild contrast enhancement (Histogram Equalization)
    ycrcb = cv2.cvtColor(denoised_image, cv2.COLOR_BGR2YCrCb)
    y, cr, cb = cv2.split(ycrcb)
    y = cv2.equalizeHist(y)
    enhanced_image = cv2.merge([y, cr, cb])
    enhanced_image = cv2.cvtColor(enhanced_image, cv2.COLOR_YCrCb2BGR)

    return enhanced_image

# Function to analyze and display selected file
def analyze_and_display(selected_file, uploaded_file):
    file_path = uploaded_file if uploaded_file else os.path.join(dataset_folder, selected_file) if selected_file else None
    if not file_path or file_path in ["❌ Dataset folder not found!", "⚠️ No images or videos found in dataset!"]:
        return "❌ No file selected!", None, None

    if file_path.lower().endswith((".jpg", ".png")):
        image = cv2.imread(file_path)
        if image is None:
            return "❌ Error: Could not load image!", None, None

        # Preprocess the image
        enhanced_image = preprocess_image(image)

        results = model(enhanced_image)
        vehicle_count = 0

        for result in results:
            for box in result.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                conf = box.conf[0].item()
                cls = int(box.cls[0].item())

                if cls in vehicle_classes:
                    vehicle_count += 1
                    cv2.rectangle(enhanced_image, (x1, y1), (x2, y2), (0, 255, 0), 3)
                    cv2.putText(enhanced_image, f"Conf: {conf:.2f}", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        analyzed_image_path = "analyzed_image.jpg"
        cv2.imwrite(analyzed_image_path, enhanced_image)

        return f"✅ Vehicles Detected: {vehicle_count}", analyzed_image_path, None

    elif file_path.lower().endswith(".mp4"):
        cap = cv2.VideoCapture(file_path)
        frame_count = 0
        total_vehicles = 0
        output_path = "output_video.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            frame_count += 1
            enhanced_frame = preprocess_image(frame)
            results = model(enhanced_frame)

            for result in results:
                for box in result.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    conf = box.conf[0].item()
                    cls = int(box.cls[0].item())

                    if cls in vehicle_classes:
                        total_vehicles += 1
                        cv2.rectangle(enhanced_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
                        cv2.putText(enhanced_frame, f"Conf: {conf:.2f}", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

            out.write(enhanced_frame)

            if frame_count >= 100:
                break

        cap.release()
        out.release()

        avg_vehicles_per_frame = total_vehicles / frame_count if frame_count else 0
        return f"✅ Avg Vehicles Per Frame: {avg_vehicles_per_frame:.2f}", None, output_path

    else:
        return "❌ Unsupported file type!", None, None

# Create Gradio Interface
with gr.Blocks() as interface:
    gr.Markdown("## Select an Existing File or Upload Your Own")

    dataset_files = gr.Dropdown(choices=list_dataset_files(), label="📂 Select a file from dataset", interactive=True)
    file_upload = gr.File(label="📤 Or Upload a New Image/Video", type="filepath")

    # Detection status comes first
    display_output = gr.Textbox(label="🔍 Detection Status")

    # Confirm Selection button is directly below Detection Status
    select_button = gr.Button("Confirm Selection")

    file_preview = gr.Image(label="🚗 Processed Image with Detections", type="filepath", interactive=False)
    video_preview = gr.Video(label="🎥 Processed Video with Detections", interactive=False)

    # Order: Detection Status → Confirm Button → Image/Video Preview
    select_button.click(analyze_and_display, inputs=[dataset_files, file_upload], outputs=[display_output, file_preview, video_preview])

# Launch the GUI
interface.launch()